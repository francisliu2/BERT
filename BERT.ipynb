{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "auahfI1vrbd9"
   },
   "source": [
    "\n",
    "# Bidirectional Encoder Representation from Transformer (BERT)\n",
    "This is a notebook of using BERT to distinguish whether a Reddit comment under the Bitcoin subreddit is posted in June 2016 or Dec 2017, where Bitcoin's price was stabilized in June 2016 and extremely volatile in Dec 2017. \n",
    "\n",
    "Ktrain, a lightweight wrapper for Keras, is used in this notebook. It allows users to train and deploy BERT easily. \n",
    "\n",
    "DO NOT RUN THIS NOTEBOOK LOCALLY UNLESS YOUR LOCAL MACHINE CONTAINS A NVIDIA GPU BETTER OR EQUIVALENT TO A GTX1060. \n",
    "\n",
    "If you still want to run this notebook, you can upload this notebook to Google Colab. Google provides a free-to-use GPU (and TPU as well). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "cmQYBd6KwM_g",
    "outputId": "2bae8fb7-e410-4c2e-dbf4-7944b40cdcfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  tree\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 40.7 kB of archives.\n",
      "After this operation, 105 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
      "Fetched 40.7 kB in 1s (33.5 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tree.\n",
      "(Reading database ... 132684 files and directories currently installed.)\n",
      "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
      "Unpacking tree (1.7.0-5) ...\n",
      "Setting up tree (1.7.0-5) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
     ]
    }
   ],
   "source": [
    "# Create file structure \n",
    "!sudo apt-get install tree\n",
    "!mkdir -p reddit_bitcoin_data/train/dec2017\n",
    "!mkdir -p reddit_bitcoin_data/train/jun2016\n",
    "!mkdir -p reddit_bitcoin_data/test/dec2017\n",
    "!mkdir -p reddit_bitcoin_data/test/jun2016\n",
    "# !tree --filelimit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSXCZqDwxMMj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "eKDzqNSRmKPn",
    "outputId": "a3a1f269-dedd-413a-977a-80da41196739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/io/gbq.py:176: FutureWarning: verbose is deprecated and will be removed in a future version. Set logging level in order to vary verbosity\n",
      "  **kwargs\n"
     ]
    }
   ],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "print('Authenticated')\n",
    "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
    "project_id = 'caramel-pager-156904' #Put your project ID here\n",
    "jun2016 = pd.io.gbq.read_gbq('''\n",
    "SELECT body FROM `fh-bigquery.reddit_comments.2016_06`\n",
    "where subreddit = 'Bitcoin' and length(body)>100\n",
    "''', project_id=project_id, verbose=False)\n",
    "\n",
    "dec2017 = pd.io.gbq.read_gbq('''\n",
    "SELECT body FROM `fh-bigquery.reddit_comments.2017_12`\n",
    "where subreddit = 'Bitcoin' and length(body)>100\n",
    "''', project_id=project_id, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Vo72_aH7nQuc",
    "outputId": "2694ddab-90ef-4b97-b358-77966825186a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258095\n",
      "32972\n"
     ]
    }
   ],
   "source": [
    "# Check how many data we have\n",
    "print(len(dec2017))\n",
    "print(len(jun2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEAkTQLkv6I4"
   },
   "outputs": [],
   "source": [
    "# Make balance dataset\n",
    "bal2017 = np.random.choice(range(0,len(dec2017)),32972, replace=False)\n",
    "dec2017_bal = dec2017.iloc[bal2017]\n",
    "dec2017_bal.reset_index(drop=True, inplace=True)\n",
    "jun2016_bal = jun2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vedIONgtyxBP"
   },
   "outputs": [],
   "source": [
    "# Seperate train test dataset\n",
    "all_id = np.array(range(0,len(dec2017_bal)))\n",
    "train_id = np.random.choice(range(0,len(dec2017_bal)),round(len(dec2017_bal)*0.8), replace=False)\n",
    "test_id = np.random.choice(np.delete(all_id,train_id), round(len(dec2017_bal)*0.2), replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wibGeCEzaXW"
   },
   "outputs": [],
   "source": [
    "# Write files according to the ktrain package requirment\n",
    "def write_txt_files(T='train', D='dec2017', pd2write = dec2017_bal, id_ = train_id):\n",
    "  folder = './reddit_bitcoin_data/%s/%s' % (T,D)\n",
    "  for id in tqdm(id_):\n",
    "    filename = str(id)+'.txt'\n",
    "    with open(os.path.join(folder,filename),'w') as outfile:\n",
    "        pd2write.iloc[id].to_string(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "x4PjAf9e48nU",
    "outputId": "8ae627d3-8a06-4772-8686-943fa89d2d7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26378/26378 [00:19<00:00, 1376.07it/s]\n",
      "100%|██████████| 6594/6594 [00:05<00:00, 1275.18it/s]\n",
      "100%|██████████| 26378/26378 [00:19<00:00, 1383.98it/s]\n",
      "100%|██████████| 6594/6594 [00:04<00:00, 1340.36it/s]\n"
     ]
    }
   ],
   "source": [
    "write_txt_files(T='train', D='dec2017', pd2write = dec2017_bal, id_ = train_id)\n",
    "write_txt_files(T='test', D='dec2017', pd2write = dec2017_bal, id_ = test_id)\n",
    "write_txt_files(T='train', D='jun2016', pd2write = jun2016_bal, id_ = train_id)\n",
    "write_txt_files(T='test', D='jun2016', pd2write = jun2016_bal, id_ = test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PpfBFylY67Lk",
    "outputId": "9b26bf01-657a-4783-b645-51929a3ab924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/dd/74108dc5359663524bb340f9ff7b10f18ab3d6f932fc0456e9291aff1e74/ktrain-0.6.0.tar.gz (173kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 2.8MB/s \n",
      "\u001b[?25hCollecting keras==2.2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 41.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.21.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.25.3)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.1.21)\n",
      "Collecting keras_bert\n",
      "  Downloading https://files.pythonhosted.org/packages/df/fe/bf46de1ef9d1395cd735d8df5402f5d837ef82cfd348a252ad8f32feeaef/keras-bert-0.80.0.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.21.0)\n",
      "Collecting eli5>=0.10.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 30.1MB/s \n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.14.0)\n",
      "Collecting langdetect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 39.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.39)\n",
      "Collecting cchardet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/a5/d073e7a0e992275d9b87e08cc3151c0ec27c718b78e6c943d264e5bd71d3/cchardet-2.1.4-cp36-cp36m-manylinux1_x86_64.whl (204kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 41.0MB/s \n",
      "\u001b[?25hCollecting networkx==2.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/08/f20aef11d4c343b557e5de6b9548761811eb16e438cee3d32b1c66c8566b/networkx-2.3.zip (1.7MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 40.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.3.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->ktrain) (1.17.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.6.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->ktrain) (2018.9)\n",
      "Collecting keras-transformer>=0.30.0\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/57/496b1eab888171b0801a0a44d3245a7874b8d1cc04c1fbfdbb5e3327fc7a/keras-transformer-0.31.0.tar.gz\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (0.8.5)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (0.10.1)\n",
      "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (19.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5>=0.10.0->ktrain) (2.10.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx==2.3->ktrain) (4.4.1)\n",
      "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.5.3)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (19.2)\n",
      "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.0->ktrain) (41.4.0)\n",
      "Collecting keras-pos-embd>=0.10.0\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
      "Collecting keras-multi-head>=0.22.0\n",
      "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
      "Collecting keras-layer-normalization>=0.12.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
      "Collecting keras-position-wise-feed-forward>=0.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
      "Collecting keras-embed-sim>=0.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5>=0.10.0->ktrain) (1.1.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.0->bokeh->ktrain) (0.46)\n",
      "Collecting keras-self-attention==0.41.0\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
      "Building wheels for collected packages: ktrain, keras-bert, seqeval, langdetect, networkx, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ktrain: filename=ktrain-0.6.0-cp36-none-any.whl size=223615 sha256=2a1b1ca04cb6e816f9047a804de20bb57b7c57fabbcd0ae9fcef883c477c3e47\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/d5/4e/5ff9bfbef0091828dc1f68f1fb4191df900fa8063d9599d5bc\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.80.0-cp36-none-any.whl size=37923 sha256=f7a4a0a90ed5044d9476b44f9e7c898a44d92235fbd1c049dc04f22a77cbadf6\n",
      "  Stored in directory: /root/.cache/pip/wheels/63/dc/87/3260cb91f3aa32c0f85c5375429a30c8fd988bbb48f5ee21b0\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=82ecc4c62ad3e673c2f1b46a8027a4544db8c8ed1f34db5f2ba00d5b0f06671e\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=b56ba960ee95649fd6404c1036bf540ec6ae55316cbad0521ef1cae685db4007\n",
      "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for networkx: filename=networkx-2.3-py2.py3-none-any.whl size=1556408 sha256=c11f37c14c724e65fa5bbdbf98c11fca21501aac7ce922e852206eaddb5844f1\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/63/64/3699be2a9d0ccdb37c7f16329acf3863fd76eda58c39c737af\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.31.0-cp36-none-any.whl size=13385 sha256=e976f1a4a97b9fa86c59edbf2ad5aa100e529226c881ea3044852ce5a0ddbef6\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=d859051ef003a6029fc23679315f6f4f65463845d985ad7fd971f98c4e909945\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=dcad33cdd373846cfd2cdbab65dd7eaff97cdcfee47cc586895aee2e2ff1084b\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=18d53386a12335b191c7e6b71a033d3a05af56231a3bd4d0cde53d9776091862\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=6f52cfa4c740196bf9eee9b65799273e56d439cf86b9400abe1b3a6ef1b9d507\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=a6b416c2734e5de774f1fade3eea2e01d91882f9581f4394024e92721de5b7ce\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=967177ff71a2ae3162ea353872e754c7e87251c81fba91e53af9d5c5c3926619\n",
      "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
      "Successfully built ktrain keras-bert seqeval langdetect networkx keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, eli5, seqeval, langdetect, cchardet, networkx, ktrain\n",
      "  Found existing installation: Keras 2.2.5\n",
      "    Uninstalling Keras-2.2.5:\n",
      "      Successfully uninstalled Keras-2.2.5\n",
      "  Found existing installation: networkx 2.4\n",
      "    Uninstalling networkx-2.4:\n",
      "      Successfully uninstalled networkx-2.4\n",
      "Successfully installed cchardet-2.1.4 eli5-0.10.1 keras-2.2.4 keras-bert-0.80.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0 ktrain-0.6.0 langdetect-1.0.7 networkx-2.3 seqeval-0.0.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Keras version: 2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ktrain\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "oFk_JVfisLbm",
    "outputId": "89fe24e9-8c85-4d41-96f8-55c72e677669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected encoding: utf-8\n",
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_folder('./reddit_bitcoin_data/', \n",
    "                                                                      maxlen=500, \n",
    "                                                                       preprocess_mode='bert',\n",
    "                                                                       train_test_names=['train', \n",
    "                                                                                         'test'],\n",
    "                                                                       classes=['dec2017', 'jun2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yN7vM_Q07ms4",
    "outputId": "a43363c5-c19a-4663-d9f4-7eec3cb63674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 500\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n",
    "learner = ktrain.get_learner(model,train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "gqBDWbJ97kCq",
    "outputId": "fb587844-1ead-4769-f96c-bb5da03c22d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-13 12:39:39--  https://box.hu-berlin.de/f/1760795d78e141c7aa58/?dl=1\n",
      "Resolving box.hu-berlin.de (box.hu-berlin.de)... 141.20.184.42\n",
      "Connecting to box.hu-berlin.de (box.hu-berlin.de)|141.20.184.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://box.hu-berlin.de/seafhttp/files/6a169b90-41c0-4527-9acc-cd615e7cb80c/mymodel [following]\n",
      "--2019-11-13 12:39:42--  https://box.hu-berlin.de/seafhttp/files/6a169b90-41c0-4527-9acc-cd615e7cb80c/mymodel\n",
      "Reusing existing connection to box.hu-berlin.de:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1314246128 (1.2G) [application/octet-stream]\n",
      "Saving to: ‘mymodel’\n",
      "\n",
      "mymodel             100%[===================>]   1.22G  1.77MB/s    in 21m 42s \n",
      "\n",
      "2019-11-13 13:01:23 (986 KB/s) - ‘mymodel’ saved [1314246128/1314246128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To get a trained model\n",
    "\n",
    "# For Unix based OS (e.g. Mac, Linux, Ubuntu etc.)\n",
    "!wget -O mymodel https://box.hu-berlin.de/f/1760795d78e141c7aa58/?dl=1\n",
    "\n",
    "# For windows machine (slower)\n",
    "# import urllib.request\n",
    "# url = 'https://box.hu-berlin.de/f/1760795d78e141c7aa58/?dl=1'\n",
    "# urllib.request.urlretrieve(url, \"mymodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVMsrnUt5nKt"
   },
   "outputs": [],
   "source": [
    "learner.load_model('mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nC9ak3BvxW5N",
    "outputId": "f9cc711f-5bac-4ed2-d1bd-637478134e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adc.json\t   'index.html?dl=1.1'\t reddit_bitcoin_data\n",
      "'index.html?dl=1'   mymodel\t\t sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mssnbhc_klNd"
   },
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "yiqXIwt57K-i",
    "outputId": "e3fc2e6c-b968-49a4-f844-db804b23ff42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.60      0.72      4160\n",
      "           1       0.70      0.93      0.80      4160\n",
      "\n",
      "    accuracy                           0.76      8320\n",
      "   macro avg       0.79      0.76      0.76      8320\n",
      "weighted avg       0.79      0.76      0.76      8320\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2495, 1665],\n",
       "       [ 309, 3851]])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(val_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "dvrINqy87pNX",
    "outputId": "deda513e-6825-48eb-adcf-45b39c9e219e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52756 samples, validate on 8320 samples\n",
      "Epoch 1/1\n",
      "52756/52756 [==============================] - 14440s 274ms/step - loss: 0.2810 - acc: 0.8799 - val_loss: 0.9408 - val_acc: 0.6389\n",
      "Train on 52756 samples, validate on 8320 samples\n",
      "Epoch 1/1\n",
      "46146/52756 [=========================>....] - ETA: 29:09 - loss: 0.1684 - acc: 0.9332"
     ]
    }
   ],
   "source": [
    "# DON'T RUN THIS IF YOU DO NOT HAVE A GPU MACHINE\n",
    "for e in range(2):\n",
    "  learner.fit(2e-5, 1)\n",
    "  learner.save_model('mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "gTdf-BI33HXC",
    "outputId": "a429c8ad-a044-4eaf-e8c4-a269d87be6f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=jun2016\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.956</b>, score <b>3.068</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.482\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.587\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 90.27%); opacity: 0.83\" title=\"0.101\">actually</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.75%); opacity: 0.92\" title=\"0.439\">price</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.67%); opacity: 0.84\" title=\"-0.158\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.75%); opacity: 0.95\" title=\"-0.584\">electricity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.37%); opacity: 0.92\" title=\"0.448\">keeps</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.87%); opacity: 0.89\" title=\"-0.348\">bitcoin</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.29%); opacity: 0.87\" title=\"-0.277\">out</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.64%); opacity: 0.82\" title=\"-0.068\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.11%); opacity: 0.81\" title=\"0.049\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.57%); opacity: 0.92\" title=\"-0.443\">hands</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.34%); opacity: 0.83\" title=\"-0.100\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.03%); opacity: 0.95\" title=\"0.577\">globalists</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 85.25%); opacity: 0.85\" title=\"0.183\">cheap</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.98%); opacity: 0.91\" title=\"-0.434\">electricity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.59%); opacity: 0.81\" title=\"-0.056\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.86%); opacity: 0.90\" title=\"0.391\">found</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.12%); opacity: 0.87\" title=\"0.260\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.43%); opacity: 0.92\" title=\"0.470\">outlying</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 83.07%); opacity: 0.86\" title=\"-0.223\">underdeveloped</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.760\">areas</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.02%); opacity: 0.82\" title=\"0.090\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.58%); opacity: 0.86\" title=\"-0.232\">lack</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.40%); opacity: 0.83\" title=\"-0.099\">significant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.78%); opacity: 0.85\" title=\"-0.191\">industrial</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.47%); opacity: 0.80\" title=\"-0.015\">commercial</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 94.06%); opacity: 0.81\" title=\"-0.050\">residential</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 95.88%); opacity: 0.81\" title=\"-0.030\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.21%); opacity: 0.81\" title=\"-0.048\">agricultural</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.67%); opacity: 0.86\" title=\"0.211\">demand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.32%); opacity: 0.85\" title=\"0.182\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.42%); opacity: 0.81\" title=\"0.034\">electricity</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.03%); opacity: 0.86\" title=\"-0.223\">proportionate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.53%); opacity: 0.91\" title=\"-0.421\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.28%); opacity: 0.83\" title=\"-0.101\">supply</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 76.51%); opacity: 0.89\" title=\"-0.355\">https</span><span style=\"opacity: 0.80\">://</span><span style=\"background-color: hsl(0, 100.00%, 84.13%); opacity: 0.85\" title=\"-0.203\">en</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 91.04%); opacity: 0.82\" title=\"0.090\">m</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 84.82%); opacity: 0.85\" title=\"-0.190\">wikipedia</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 90.27%); opacity: 0.83\" title=\"-0.101\">org</span><span style=\"opacity: 0.80\">/</span><span style=\"background-color: hsl(0, 100.00%, 85.30%); opacity: 0.85\" title=\"-0.182\">wiki</span><span style=\"opacity: 0.80\">/</span><span style=\"background-color: hsl(120, 100.00%, 96.81%); opacity: 0.81\" title=\"0.020\">electricity_pricing</span><span style=\"opacity: 0.80\">#</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"\"\"Actually price of electricity keeps bitcoin out of the hands\n",
    "            of globalists. Cheap electricity is found in outlying, underdeveloped\n",
    "            areas that lack significant industrial, commercial, residential,\n",
    "            or agricultural demand for electricity proportionate to supply.\n",
    "            \\n\\nhttps://en.m.wikipedia.org/wiki/Electricity_pricing#\n",
    "\"\"\"\n",
    "predictor.explain(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the code correctly, you will get the below result\n",
    "<img src=\"text1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "b7FGVGSKvQdg",
    "outputId": "a711d6bb-2665-4759-9a29-3d3d5acc2b1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=dec2017\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.997</b>, score <b>-5.673</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.700\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.027\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 94.29%); opacity: 0.81\" title=\"-0.246\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.17%); opacity: 0.80\" title=\"0.048\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.58%); opacity: 0.81\" title=\"0.228\">money</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.54%); opacity: 0.82\" title=\"0.361\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.971\">binance</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.14%); opacity: 0.81\" title=\"0.141\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.90%); opacity: 0.82\" title=\"-0.479\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.74%); opacity: 0.84\" title=\"-0.820\">pretty</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.64%); opacity: 0.84\" title=\"-0.742\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.61%); opacity: 0.81\" title=\"0.289\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.59%); opacity: 0.81\" title=\"-0.118\">leave</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.87%); opacity: 0.81\" title=\"-0.155\">as</span><span style=\"opacity: 0.80\"> btc </span><span style=\"background-color: hsl(120, 100.00%, 98.25%); opacity: 0.80\" title=\"0.046\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.06%); opacity: 0.81\" title=\"0.145\">if</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.32%); opacity: 0.80\" title=\"-0.083\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.12%); opacity: 0.82\" title=\"-0.390\">see</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.37%); opacity: 0.81\" title=\"0.129\">something</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.02%); opacity: 0.80\" title=\"0.097\">taking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.32%); opacity: 0.81\" title=\"0.245\">off</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.08%); opacity: 0.81\" title=\"-0.199\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.58%); opacity: 0.81\" title=\"-0.228\">buy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.18%); opacity: 0.80\" title=\"0.015\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.69%); opacity: 0.80\" title=\"0.067\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.76%); opacity: 0.81\" title=\"-0.161\">then</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.45%); opacity: 0.80\" title=\"-0.078\">sell</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.11%); opacity: 0.81\" title=\"-0.198\">before</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.85%); opacity: 0.80\" title=\"0.061\">bed</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.197\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.17%); opacity: 0.81\" title=\"-0.139\">been</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.82%); opacity: 0.81\" title=\"0.158\">working</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.86%); opacity: 0.81\" title=\"0.212\">out</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.28%); opacity: 0.80\" title=\"-0.044\">pretty</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.59%); opacity: 0.80\" title=\"0.006\">well</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.18%); opacity: 0.81\" title=\"-0.193\">so</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.18%); opacity: 0.81\" title=\"-0.193\">far</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 97.07%); opacity: 0.80\" title=\"0.095\">it</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 99.32%); opacity: 0.80\" title=\"0.012\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.85%); opacity: 0.81\" title=\"0.105\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.46%); opacity: 0.81\" title=\"0.124\">most</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.66%); opacity: 0.81\" title=\"-0.286\">likely</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.01%); opacity: 0.81\" title=\"0.264\">going</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.84%); opacity: 0.81\" title=\"0.213\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.26%); opacity: 0.80\" title=\"0.086\">end</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.17%); opacity: 0.82\" title=\"-0.459\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.01%); opacity: 0.82\" title=\"0.329\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.18%); opacity: 0.93\" title=\"2.610\">ripple</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.28%); opacity: 0.80\" title=\"0.013\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.91%); opacity: 0.81\" title=\"0.270\">trx</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.16%); opacity: 0.81\" title=\"0.140\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.55%); opacity: 0.80\" title=\"0.073\">some</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.14%); opacity: 0.80\" title=\"-0.092\">point</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.14%); opacity: 0.80\" title=\"-0.092\">tho</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = \"\"\"I have money in binance that I pretty much just leave as btc and if\n",
    "           I see something taking off I buy in and then sell before bed. \n",
    "           Has been working out pretty well so far. It's all most likely \n",
    "           going to end up in Ripple and trx at some point tho.\n",
    "\"\"\"\n",
    "predictor.explain(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-G6g1WNxyRf"
   },
   "source": [
    "If you run the code correctly, you will get the below result\n",
    "<img src=\"text2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k85GW0ha_wfZ"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
